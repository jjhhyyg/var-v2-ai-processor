# 异常事件生成逻辑详细说明

## 整体架构

异常事件生成系统采用**三阶段处理流程**：

```
YOLO检测 → 物体追踪(BoT-SORT) → 追踪合并 → 事件生成
   ↓              ↓                  ↓           ↓
原始检测      track_id分配      ID统一化      异常事件
```

### 1. 检测与追踪阶段 (EventDetector)

**文件**: `event_detector.py`

**职责**:

- 接收YOLO检测结果 + BoT-SORT追踪ID
- 记录每个物体的完整生命周期（首次出现→持续追踪→消失）
- 维护物体轨迹数据

**核心数据结构**:

```python
track_info = {
    'track_id': int,              # BoT-SORT分配的追踪ID
    'class_name': str,            # 类别名称（如"粘连物"）
    'class_id': int,              # 类别ID
    'first_frame': int,           # 首次出现帧号
    'last_frame': int,            # 最后出现帧号
    'first_time': float,          # 首次出现时间(秒)
    'last_time': float,           # 最后出现时间(秒)
    'trajectory': [               # 轨迹数据
        {
            'frame': int,         # 帧号
            'bbox': [x1,y1,x2,y2], # 边界框
            'confidence': float    # 置信度
        }
    ]
}
```

**处理逻辑**:

```python
def process_detections(frame_number, detections):
    """
    每帧调用一次，处理当前帧的检测结果
    
    1. 新物体出现:
       - 创建新的track_info
       - 记录首次出现的帧号、时间、位置
    
    2. 已知物体持续出现:
       - 更新last_frame、last_time
       - 添加轨迹点到trajectory
    
    3. 物体消失:
       - 从active_tracks移到completed_tracks
       - 保留完整追踪记录
    
    4. 物体重新出现:
       - 从completed_tracks恢复到active_tracks
       - 继续更新轨迹（允许轨迹中断）
    """
```

**未追踪物体处理**:

```python
# 对于track_id为None或-1的检测（BoT-SORT未追踪）
if track_id is None or track_id == -1:
    # 分配临时负数ID，避免与正常ID冲突
    track_id = -(1000000 + counter)
```

---

### 2. 追踪合并阶段 (TrackingMerger)

**文件**: `tracking_merger.py`

**背景问题**:
虽然使用了BoT-SORT（带ReID的追踪器），但在**极端形变场景**下仍会失效：

- **粘连物脱落**: 形状从块状→拉长→碎片，外观特征剧变
- **锭冠脱落**: 从附着→分离→下落，位置和形状急剧变化
- **电弧遮挡**: 强光遮挡后物体外观改变

**解决策略**:
在BoT-SORT追踪结果基础上进行**后处理**，通过更长时间窗口和宽松约束重新关联断裂的追踪片段。

**核心参数**:

```python
TrackingMerger(
    max_frame_gap=15,          # 最大帧间隔（约0.5秒）
                               # BoT-SORT的track_buffer=100帧
                               # 这里设为15%用于连接超出buffer的情况
    
    max_distance=100.0,        # 最大中心点距离（像素）
                               # 粘连物脱落可能快速移动
    
    min_iou=0.1,              # 最小IoU阈值
                               # 比BoT-SORT的0.5更宽松，允许形变
    
    allow_shape_change=True,   # 允许形状变化
                               # 适配脱落场景的渐进形变
    
    max_shape_change_rate=0.5  # 最大形状变化率
)
```

**关联得分计算**:

```python
def calculate_association_score(obj1, obj2):
    """
    计算两个追踪片段的关联得分（0-1，越高越可能是同一物体）
    
    返回: (得分, 原因说明)
    """
    
    # 1. 前置检查（不满足直接返回0分）
    if obj1.category != obj2.category:
        return (0.0, "类别不匹配")
    
    if obj1.last_frame >= obj2.first_frame:
        # 时间重叠 > 3帧，不应合并
        return (0.0, "时间重叠过多")
    
    frame_gap = obj2.first_frame - obj1.last_frame
    if frame_gap > max_frame_gap:  # 默认15帧
        return (0.0, f"时间间隔过大({frame_gap}帧)")
    
    distance = bbox1_last.distance_to(bbox2_first)
    if distance > max_distance:  # 默认100像素
        return (0.0, f"距离过远({distance:.1f}px)")
    
    # 2. 多维度得分计算（加权平均）
    
    # 2.1 空间距离得分 (权重25%)
    distance_score = 1.0 - (distance / max_distance)
    
    # 2.2 位置预测得分 (权重20%)
    # 基于obj1的运动速度预测obj2首帧的位置
    predicted_bbox = obj1.predict_position(obj2.first_frame)
    prediction_distance = predicted_bbox.distance_to(bbox2_first)
    prediction_score = 1.0 - min(prediction_distance / max_distance, 1.0)
    
    # 2.3 IoU得分 (权重15%)
    iou = bbox1_last.iou(bbox2_first)
    iou_score = iou / min_iou if iou > 0 else 0.0
    
    # 2.4 速度一致性得分 (权重15%)
    # 计算速度向量的余弦相似度
    v1 = obj1.get_velocity()  # (vx, vy) 像素/帧
    v2 = obj2.get_velocity()
    cos_sim = cosine_similarity(v1, v2)
    velocity_score = (cos_sim + 1) / 2  # 归一化到0-1
    
    # 2.5 时间连续性得分 (权重20%)
    time_score = 1.0 - (frame_gap / max_frame_gap)
    
    # 2.6 形状变化容忍度 (权重5%)
    # 如果obj1正在发生形状变化（可能在脱落），给予额外分数
    if obj1.get_shape_change_rate() > 0.1:
        shape_bonus = 0.2
    else:
        shape_bonus = 0.0
    
    # 3. 综合得分
    total_score = (
        distance_score * 0.25 +
        prediction_score * 0.20 +
        min(iou_score, 1.0) * 0.15 +
        velocity_score * 0.15 +
        time_score * 0.20 +
        shape_bonus * 0.05
    )
    
    return (total_score, reason_string)
```

**合并算法**:

```python
def merge_objects(threshold=0.5):
    """
    使用贪心算法构建追踪链
    
    1. 按类别分组处理
    2. 按首帧排序（保证时间顺序）
    3. 计算所有可能的关联对 (i, j) 及其得分
    4. 按得分从高到低排序
    5. 贪心构建追踪链:
       - 优先连接高分对
       - 一个物体只能属于一条链
       - 链中物体必须时间连续
    6. 输出合并组
    
    示例:
    原始追踪: [A1, A2, A3, B1, B2]
    关联得分: (A1,A2)=0.8, (A2,A3)=0.7, (B1,B2)=0.6
    结果: [[A1,A2,A3], [B1,B2]]
    """
```

**合并结果**:

```python
unified_object = {
    'trackingId': group[0].tracking_id,  # 使用第一个的ID
    'objectId': group[0].object_id,      # 统一ID
    'category': category,
    'firstFrame': merged_first_frame,
    'lastFrame': merged_last_frame,
    'trajectory': [
        # 合并所有片段的轨迹，按帧号排序
        # 同一帧有多个检测时，选择置信度高的
    ],
    'mergedFrom': [obj.tracking_id for obj in group],  # 记录合并来源
    'mergedObjectIds': [obj.object_id for obj in group]
}
```

---

### 3. 事件生成阶段 (AnomalyEventGenerator)

**文件**: `anomaly_event_generator.py`

**输入**: 合并后的统一追踪对象列表  
**输出**: 符合后端要求的异常事件列表

#### 3.1 时间段事件生成

**原则**: 对于同类物体，取**最早出现**和**最晚消失**的时间作为事件时间段

**算法**:

```python
def generate_events(tracking_objects, video_filename, total_frames):
    """
    为每个物体类别生成时间段事件
    """
    
    # 1. 按类别分组
    objects_by_category = {
        'ADHESION': [...],
        'CROWN': [...],
        'POOL_NOT_REACHED': [...],
        ...
    }
    
    # 2. 为每个类别生成事件
    for category, objects in objects_by_category.items():
        # 2.1 找最早出现的物体（前5秒无此类物体）
        first_obj = find_first_appearance(objects, total_frames)
        
        # 2.2 找最晚消失的物体（后5秒无此类物体）
        last_obj = find_last_appearance(objects, total_frames)
        
        # 2.3 生成时间段事件
        if first_obj and last_obj:
            event = {
                'eventType': get_event_type(category),
                'startFrame': first_obj['firstFrame'],
                'endFrame': last_obj['lastFrame'],
                'objectId': None,    # 按要求留空
                'metadata': None     # 时间段事件不需要metadata
            }
```

**最早出现判断** (`find_first_appearance`):

```python
def find_first_appearance(objects, total_frames):
    """
    找出最早出现的物体（满足：前5秒无此类物体）
    
    条件:
    1. 该物体是同类中首次出现帧最小的
    2. 且满足以下之一:
       - 起始帧 <= 5秒（视频开始处）
       - 前5秒帧范围内无其他同类物体
    
    时间窗口: 5秒 × fps帧
    """
    # 按起始帧排序，取第一个
    first_obj = objects[0]
    
    # 检查前5秒是否有同类物体
    time_window_frames = int(5 * fps)
    
    if first_obj['firstFrame'] <= time_window_frames:
        # 在视频开始5秒内，直接返回
        return first_obj
    
    # 检查 [firstFrame - 5秒, firstFrame) 范围内是否有其他物体
    window_start = first_obj['firstFrame'] - time_window_frames
    has_object_in_window = any(
        obj['lastFrame'] >= window_start 
        and obj['firstFrame'] < first_obj['firstFrame']
        for obj in objects
    )
    
    return first_obj if not has_object_in_window else None
```

**最晚消失判断** (`find_last_appearance`):

```python
def find_last_appearance(objects, total_frames):
    """
    找出最晚消失的物体（满足：后5秒无此类物体）
    
    条件:
    1. 该物体是同类中最后消失帧最大的
    2. 且满足以下之一:
       - 结束帧 >= total_frames - 5秒（视频结尾处）
       - 后5秒帧范围内无其他同类物体
    """
    # 按结束帧排序，取最后一个
    last_obj = sorted(objects, key=lambda x: x['lastFrame'])[-1]
    
    time_window_frames = int(5 * fps)
    
    if last_obj['lastFrame'] >= total_frames - time_window_frames:
        # 在视频最后5秒内，直接返回
        return last_obj
    
    # 检查 (lastFrame, lastFrame + 5秒] 范围内是否有其他物体
    window_end = min(total_frames, last_obj['lastFrame'] + time_window_frames)
    has_object_in_window = any(
        obj['firstFrame'] <= window_end 
        and obj['lastFrame'] > last_obj['lastFrame']
        for obj in objects
    )
    
    return last_obj if not has_object_in_window else None
```

**类别到事件类型映射**:

```python
CATEGORY_TO_EVENT = {
    'POOL_NOT_REACHED': 'POOL_NOT_REACHED',  # 熔池未打开
    'ADHESION': 'ADHESION_FORMED',           # 粘连物出现
    'CROWN': 'CROWN_DROPPED',                # 锭冠脱落
    'GLOW': 'GLOW',                          # 辉光
    'SIDE_ARC': 'SIDE_ARC',                  # 侧弧
    'CREEPING_ARC': 'CREEPING_ARC'           # 爬行弧
}
```

#### 3.2 粘连物脱落位置判断

**目标**: 判断粘连物脱落到**熔池**还是**结晶器**

**视角判断**:

```python
def determine_video_perspective(video_filename):
    """
    根据文件名判断视角
    
    左视角标识: ['left', '_l_', '_l.', 'l_', '左']
    右视角标识: ['right', '_r_', '_r.', 'r_', '右']
    默认: 'LEFT'
    """
```

**脱落位置判断逻辑**:

```python
def analyze_adhesion_drop(adhesion_obj, video_perspective):
    """
    分析粘连物脱落位置
    
    前置条件:
    1. 轨迹长度 >= 2帧
    2. 持续时间 >= 10帧（过滤噪声）
    
    判断逻辑:
    - 左视角:
      ├─ 向左飘落 或 突然消失 → 结晶器 (crystallizer)
      └─ 向右飘落 → 熔池 (pool)
    
    - 右视角:
      ├─ 向左飘落 → 熔池 (pool)
      └─ 向右飘落 或 突然消失 → 结晶器 (crystallizer)
    """
    
    # 1. 取最后10帧（或全部）的轨迹
    num_frames = min(10, len(trajectory))
    recent_trajectory = trajectory[-num_frames:]
    
    # 2. 计算水平移动方向
    centers = [get_bbox_center(t['bbox']) for t in recent_trajectory]
    horizontal_movement = sum(
        centers[i][0] - centers[i-1][0] 
        for i in range(1, len(centers))
    )
    
    # 3. 判断是否突然消失
    # 条件: 最后一帧置信度 < 平均置信度 × 50%
    sudden_disappearance = False
    if len(trajectory) >= 3:
        last_conf = trajectory[-1]['confidence']
        avg_conf = mean([t['confidence'] for t in trajectory[:-1]])
        if last_conf < avg_conf * 0.5:
            sudden_disappearance = True
    
    # 4. 根据视角和运动判断脱落位置
    if video_perspective == 'LEFT':
        if horizontal_movement < -5 or sudden_disappearance:
            return 'crystallizer'  # 向左或突然消失 → 结晶器
        elif horizontal_movement > 5:
            return 'pool'  # 向右 → 熔池
    else:  # RIGHT
        if horizontal_movement < -5:
            return 'pool'  # 向左 → 熔池
        elif horizontal_movement > 5 or sudden_disappearance:
            return 'crystallizer'  # 向右或突然消失 → 结晶器
    
    return None  # 无法判断
```

**生成脱落事件**:

```python
if drop_location:
    event = {
        'eventType': 'ADHESION_DROPPED',
        'startFrame': adhesion_obj['firstFrame'],
        'endFrame': adhesion_obj['lastFrame'],
        'objectId': None,  # 按要求留空
        'metadata': {
            'dropped_location': drop_location  # 只有这一个字段
        }
    }
```

---

## 完整数据流示例

### 输入: YOLO检测 + BoT-SORT追踪

```python
# 第1帧
detections = [
    {'track_id': 1, 'class_name': '粘连物', 'bbox': [100,200,150,250], 'confidence': 0.85}
]

# 第2-50帧: 粘连物持续追踪（track_id=1）

# 第51帧: 粘连物消失（形状剧变，BoT-SORT丢失）

# 第55帧: 粘连物以新ID重新被检测到
detections = [
    {'track_id': 2, 'class_name': '粘连物', 'bbox': [105,210,155,260], 'confidence': 0.80}
]
```

### 阶段1: EventDetector记录

```python
tracking_objects = [
    {
        'objectId': 1,
        'category': 'ADHESION',
        'firstFrame': 1,
        'lastFrame': 50,
        'trajectory': [...]  # 50个轨迹点
    },
    {
        'objectId': 2,
        'category': 'ADHESION',
        'firstFrame': 55,
        'lastFrame': 100,
        'trajectory': [...]  # 45个轨迹点
    }
]
```

### 阶段2: TrackingMerger合并

```python
# 计算关联得分
score, reason = calculate_association_score(obj1, obj2)
# score = 0.65 (高分，因为时间连续、位置接近)

# 合并结果
unified_objects = [
    {
        'objectId': 1,  # 使用第一个的ID
        'category': 'ADHESION',
        'firstFrame': 1,
        'lastFrame': 100,
        'trajectory': [...]  # 95个轨迹点（合并后）
        'mergedFrom': ['1', '2'],
        'mergedObjectIds': [1, 2]
    }
]
```

### 阶段3: AnomalyEventGenerator生成事件

```python
events = [
    # 1. 粘连物出现时间段事件
    {
        'eventType': 'ADHESION_FORMED',
        'startFrame': 1,    # 最早出现
        'endFrame': 100,    # 最晚消失
        'objectId': None,
        'metadata': None
    },
    
    # 2. 粘连物脱落位置事件
    {
        'eventType': 'ADHESION_DROPPED',
        'startFrame': 1,
        'endFrame': 100,
        'objectId': None,
        'metadata': {
            'dropped_location': 'pool'  # 判断为熔池
        }
    }
]
```

---

## 关键设计决策

### 1. 为什么需要追踪合并？

**问题**: BoT-SORT虽然有ReID功能，但在极端形变时仍会失效  
**解决**: 后处理阶段通过更长时间窗口和宽松约束重新关联

### 2. 为什么时间段事件不包含objectId？

**原因**:

- 一个时间段可能包含多个同类物体
- 事件描述的是"这个时间段内有粘连物"，而非"某个特定粘连物"
- 后端关注的是异常发生的时间范围，不是具体是哪个物体

### 3. 为什么粘连物脱落需要单独判断？

**原因**:

- 脱落位置（熔池/结晶器）是重要的工艺参数
- 需要结合视频视角和物体运动方向综合判断
- 不同脱落位置代表不同的问题严重程度

### 4. 为什么允许轨迹中断？

**原因**:

- 真实场景中物体可能被短暂遮挡（电弧、烟雾）
- EventDetector允许物体"消失→重新出现"
- TrackingMerger负责重新关联这些断裂片段

---

## 参数调优建议

### BoT-SORT参数 (`botsort.yaml`)

```yaml
track_buffer: 100        # 失踪轨迹保留时间（帧）
                        # 约3-4秒，足够应对大部分遮挡
                        
match_thresh: 0.5       # ReID匹配阈值
                        # 越高越严格，降低误匹配但增加ID切换

proximity_thresh: 0.5   # 位置相似度阈值
appearance_thresh: 0.25 # 外观相似度阈值
```

### TrackingMerger参数

```python
max_frame_gap: 15       # 通常设为track_buffer的10-20%
                        # 太大会误合并，太小会漏合并
                        
max_distance: 100       # 根据分辨率和物体运动速度调整
                        # 1080p视频建议100-200像素
                        
association_threshold: 0.5  # 合并决策阈值
                           # 越高越保守，降低误合并
```

### AnomalyEventGenerator参数

```python
time_window_frames: fps * 5  # 5秒时间窗口
                             # 根据异常事件的典型持续时间调整
                             
min_duration_frames: 10      # 最小持续帧数
                             # 过滤短暂噪声检测
```

---

## 日志输出示例

```
[INFO] AnomalyEventGenerator initialized with fps=30.0, time_window=150 frames
[INFO] Video perspective determined: LEFT (filename: sample_left_20250110.mp4)
[INFO] Generated event for category ADHESION: ADHESION_FORMED, frames 45-320, 2 objects
[INFO] Generated adhesion drop event: objectId=1, location=pool
[INFO] Generated event for category CROWN: CROWN_DROPPED, frames 180-250, 1 objects
[INFO] Generated 3 anomaly events from 5 tracking objects
```

---

## 总结

异常事件生成系统通过**三阶段流水线**处理：

1. **EventDetector**: 记录原始追踪数据（配合BoT-SORT）
2. **TrackingMerger**: 修复ID断裂（后处理合并）
3. **AnomalyEventGenerator**: 生成符合业务需求的事件

**核心创新**:

- 追踪合并算法弥补BoT-SORT在极端形变下的不足
- 多维度关联得分（空间+时间+运动+形状）
- 粘连物脱落位置的视角感知判断

**设计优势**:

- 模块化设计，各阶段职责清晰
- 可调参数丰富，适应不同场景
- 详细日志输出，便于调试和优化
