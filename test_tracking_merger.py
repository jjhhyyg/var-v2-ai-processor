"""
è¿½è¸ªå¯¹è±¡åˆå¹¶æµ‹è¯•è„šæœ¬

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨tracking_mergeræ¨¡å—è§£å†³ç²˜è¿ç‰©/é”­å† è„±è½è¿‡ç¨‹ä¸­IDæ–­è£‚çš„é—®é¢˜

ä½œè€…ï¼šä¾¯é˜³æ´‹
æ—¥æœŸï¼š2025-10-10
"""

import sys
import requests
import json
from analyzer.tracking_merger import process_tracking_objects, TrackingMerger
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def test_tracking_merger(task_id: str, backend_url: str = "http://localhost:8080"):
    """
    æµ‹è¯•è¿½è¸ªå¯¹è±¡åˆå¹¶åŠŸèƒ½
    
    å‚æ•°:
        task_id: ä»»åŠ¡ID
        backend_url: åç«¯URL
    """
    print("="*80)
    print(f"è¿½è¸ªå¯¹è±¡åˆå¹¶æµ‹è¯• - ä»»åŠ¡ID: {task_id}")
    print("="*80)
    
    # 1. è·å–åŸå§‹è¿½è¸ªæ•°æ®
    print("\næ­¥éª¤1: è·å–åŸå§‹è¿½è¸ªæ•°æ®...")
    url = f"{backend_url}/api/tasks/{task_id}/result"
    response = requests.get(url)
    response.raise_for_status()
    
    data = response.json()
    if data['code'] != 200:
        raise Exception(f"APIè¿”å›é”™è¯¯: {data['message']}")
    
    result_data = data['data']
    tracking_objects = result_data.get('trackingObjects', [])
    
    print(f"  åŸå§‹è¿½è¸ªå¯¹è±¡æ•°: {len(tracking_objects)}")
    
    # ç»Ÿè®¡åŸå§‹å¯¹è±¡
    positive_ids = [obj for obj in tracking_objects if obj['objectId'] >= 0]
    negative_ids = [obj for obj in tracking_objects if obj['objectId'] < 0]
    
    print(f"  æ­£IDå¯¹è±¡æ•°ï¼ˆæŒç»­è¿½è¸ªï¼‰: {len(positive_ids)}")
    print(f"  è´ŸIDå¯¹è±¡æ•°ï¼ˆçŸ­æš‚æ£€æµ‹ï¼‰: {len(negative_ids)}")
    
    # 2. åº”ç”¨åˆå¹¶ç®—æ³•
    print("\næ­¥éª¤2: åº”ç”¨è¿½è¸ªå¯¹è±¡åˆå¹¶ç®—æ³•...")
    print("  é…ç½®å‚æ•°:")
    print("    - æœ€å¤§å¸§é—´éš”: 15å¸§")
    print("    - æœ€å¤§ç©ºé—´è·ç¦»: 100åƒç´ ")
    print("    - å…³è”å¾—åˆ†é˜ˆå€¼: 0.5")
    print("    - å…è®¸å½¢çŠ¶å˜åŒ–: True (é€‚åº”ç²˜è¿ç‰©è„±è½)")
    
    unified_objects, report = process_tracking_objects(
        tracking_objects,
        max_frame_gap=15,
        max_distance=100.0,
        association_threshold=0.5
    )
    
    # 3. æ˜¾ç¤ºåˆå¹¶æŠ¥å‘Š
    print("\næ­¥éª¤3: åˆå¹¶ç»“æœæŠ¥å‘Š")
    print("-"*80)
    print(f"  åŸå§‹å¯¹è±¡æ•°: {report['total_original_objects']}")
    print(f"  åˆå¹¶åå¯¹è±¡æ•°: {report['total_unified_objects']}")
    print(f"  åˆå¹¶ç»„æ•°: {report['merged_groups']}")
    print(f"  å•ç‹¬å¯¹è±¡æ•°: {report['single_objects']}")
    print(f"  åˆå¹¶ç‡: {report['merge_rate']}")
    
    # æ˜¾ç¤ºåˆå¹¶è¯¦æƒ…
    if report['merge_details']:
        print(f"\n  åˆå¹¶è¯¦æƒ…ï¼ˆå…±{len(report['merge_details'])}ç»„ï¼‰:")
        for detail in report['merge_details'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"\n    ç»„ {detail['group_id']}:")
            print(f"      ç»Ÿä¸€ID: {detail['unified_id']}")
            print(f"      ç±»åˆ«: {detail['category']}")
            print(f"      åˆå¹¶å¯¹è±¡æ•°: {detail['object_count']}")
            print(f"      åŸå§‹ID: {detail['original_ids']}")
            print(f"      å¸§èŒƒå›´: {detail['frame_range'][0]}-{detail['frame_range'][1]} (å…±{detail['total_frames']}å¸§)")
    
    # 4. å¯¹æ¯”åˆ†æ
    print("\næ­¥éª¤4: å¯¹æ¯”åˆ†æ")
    print("-"*80)
    
    # æ‰¾å‡ºåˆå¹¶æ•ˆæœæœ€æ˜¾è‘—çš„ä¾‹å­
    if report['merge_details']:
        max_merge = max(report['merge_details'], key=lambda x: x['object_count'])
        print(f"\n  æœ€æ˜¾è‘—çš„åˆå¹¶æ¡ˆä¾‹:")
        print(f"    ç»Ÿä¸€ID: {max_merge['unified_id']}")
        print(f"    ç±»åˆ«: {max_merge['category']}")
        print(f"    åˆå¹¶äº† {max_merge['object_count']} ä¸ªåŸå§‹è¿½è¸ªç‰‡æ®µ")
        print(f"    åŸå§‹IDåˆ—è¡¨: {max_merge['original_ids']}")
        print(f"    å®Œæ•´è¿½è¸ªèŒƒå›´: ç¬¬{max_merge['frame_range'][0]}å¸§ åˆ° ç¬¬{max_merge['frame_range'][1]}å¸§")
        print(f"    æ€»æŒç»­æ—¶é—´: {max_merge['total_frames']}å¸§")
        print(f"\n  âœ… è§£é‡Š: è¿™ä¸ªç‰©ä½“åŸæœ¬è¢«åˆ†å‰²æˆ{max_merge['object_count']}ä¸ªä¸åŒçš„IDï¼Œ")
        print(f"          ç°åœ¨é€šè¿‡åˆå¹¶ç®—æ³•è¯†åˆ«ä¸ºåŒä¸€ä¸ªç‰©ä½“ï¼Œç»´æŒç»Ÿä¸€ID {max_merge['unified_id']}")
    
    # 5. ä¿å­˜ç»“æœ
    print("\næ­¥éª¤5: ä¿å­˜åˆå¹¶ç»“æœ...")
    
    # ä¿å­˜ç»Ÿä¸€åçš„è¿½è¸ªå¯¹è±¡
    output_file = f"unified_tracking_{task_id}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'task_id': task_id,
            'task_name': result_data['name'],
            'original_count': len(tracking_objects),
            'unified_count': len(unified_objects),
            'merge_report': report,
            'unified_objects': unified_objects
        }, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ… ç»Ÿä¸€åçš„è¿½è¸ªå¯¹è±¡å·²ä¿å­˜åˆ°: {output_file}")
    
    # ä¿å­˜åˆå¹¶æŠ¥å‘Š
    report_file = f"merge_report_{task_id}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"  âœ… åˆå¹¶æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    # 6. ä½¿ç”¨å»ºè®®
    print("\næ­¥éª¤6: é›†æˆå»ºè®®")
    print("-"*80)
    print("\n  ğŸ“‹ å¦‚ä½•åœ¨åå¤„ç†ä¸­ä½¿ç”¨:")
    print("     1. åœ¨AIæ¨¡å—å®Œæˆè¿½è¸ªåï¼Œè°ƒç”¨æ­¤åˆå¹¶ç®—æ³•")
    print("     2. ä½¿ç”¨ç»Ÿä¸€åçš„è¿½è¸ªå¯¹è±¡æ›¿ä»£åŸå§‹è¿½è¸ªæ•°æ®")
    print("     3. åŸºäºç»Ÿä¸€IDæ£€æµ‹å¼‚å¸¸äº‹ä»¶ï¼ˆå¦‚ç²˜è¿ç‰©æŒç»­æ—¶é—´ã€è„±è½äº‹ä»¶ç­‰ï¼‰")
    print("\n  ğŸ“‹ å‚æ•°è°ƒä¼˜å»ºè®®:")
    print("     - max_frame_gap: æ ¹æ®è§†é¢‘å¸§ç‡è°ƒæ•´ï¼Œå¸§ç‡è¶Šé«˜å¯ä»¥è®¾ç½®è¶Šå¤§")
    print("     - max_distance: æ ¹æ®ç‰©ä½“è¿åŠ¨é€Ÿåº¦è°ƒæ•´ï¼Œç§»åŠ¨å¿«çš„ç‰©ä½“éœ€è¦æ›´å¤§å€¼")
    print("     - association_threshold: 0.4-0.6ä¹‹é—´ï¼Œè¶Šä½åˆå¹¶è¶Šæ¿€è¿›")
    print("\n  ğŸ“‹ ç‰¹æ®Šåœºæ™¯å¤„ç†:")
    print("     - ç²˜è¿ç‰©è„±è½: ç®—æ³•å·²è€ƒè™‘å½¢çŠ¶å˜åŒ–ï¼Œå¯ä»¥è¿½è¸ªè„±è½å…¨è¿‡ç¨‹")
    print("     - é”­å† è„±è½: é€šè¿‡è¿åŠ¨é¢„æµ‹å’Œä½ç½®è¿ç»­æ€§ï¼Œå³ä½¿å½¢å˜å¤§ä¹Ÿèƒ½ä¿æŒID")
    print("     - é®æŒ¡æ¢å¤: çŸ­æš‚æ¶ˆå¤±åé‡æ–°å‡ºç°çš„ç‰©ä½“ä¼šè¢«æ­£ç¡®å…³è”")
    
    print("\n" + "="*80)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*80)
    
    return unified_objects, report


def compare_before_after(task_id: str, backend_url: str = "http://localhost:8080"):
    """å¯¹æ¯”åˆå¹¶å‰åçš„å·®å¼‚"""
    
    # è·å–åŸå§‹æ•°æ®
    url = f"{backend_url}/api/tasks/{task_id}/result"
    response = requests.get(url)
    data = response.json()['data']
    tracking_objects = data.get('trackingObjects', [])
    
    # åˆå¹¶å¤„ç†
    unified_objects, report = process_tracking_objects(tracking_objects)
    
    print("\nå¯¹æ¯”åˆ†æï¼šåˆå¹¶å‰ vs åˆå¹¶å")
    print("="*80)
    
    # æ‰¾ä¸€ä¸ªè¢«åˆå¹¶çš„ä¾‹å­
    for detail in report['merge_details']:
        if detail['object_count'] >= 3:  # è‡³å°‘åˆå¹¶äº†3ä¸ª
            print(f"\næ¡ˆä¾‹ï¼šç»Ÿä¸€ID {detail['unified_id']} ({detail['category']})")
            print("-"*80)
            
            print(f"\nã€åˆå¹¶å‰ã€‘{detail['object_count']} ä¸ªç‹¬ç«‹çš„è¿½è¸ªç‰‡æ®µ:")
            for orig_id in detail['original_ids']:
                orig_obj = next(obj for obj in tracking_objects if obj['objectId'] == orig_id)
                print(f"  ID {orig_id:>6}: å¸§ {orig_obj['firstFrame']:>4} - {orig_obj['lastFrame']:>4} "
                      f"(æŒç»­ {orig_obj['lastFrame']-orig_obj['firstFrame']+1:>3}å¸§)")
            
            print(f"\nã€åˆå¹¶åã€‘1 ä¸ªè¿ç»­çš„è¿½è¸ªå¯¹è±¡:")
            unified_obj = next(obj for obj in unified_objects if obj['objectId'] == detail['unified_id'])
            print(f"  ID {detail['unified_id']:>6}: å¸§ {unified_obj['firstFrame']:>4} - {unified_obj['lastFrame']:>4} "
                  f"(æŒç»­ {unified_obj['lastFrame']-unified_obj['firstFrame']+1:>3}å¸§)")
            
            print(f"\nâœ… æ•ˆæœ: å°†æ–­è£‚çš„è¿½è¸ªç‰‡æ®µé‡æ–°è¿æ¥ï¼Œç»´æŒäº†ç‰©ä½“çš„IDä¸€è‡´æ€§")
            break


def main():
    """ä¸»å‡½æ•°"""
    # è·å–å·²å®Œæˆçš„ä»»åŠ¡
    print("æ­£åœ¨è·å–å·²å®Œæˆçš„ä»»åŠ¡åˆ—è¡¨...")
    response = requests.get("http://localhost:8080/api/tasks?status=COMPLETED&size=5")
    tasks_data = response.json()
    
    if tasks_data['code'] != 200:
        print(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {tasks_data['message']}")
        return
    
    tasks = tasks_data['data']['items']
    
    if not tasks:
        print("æ²¡æœ‰æ‰¾åˆ°å·²å®Œæˆçš„ä»»åŠ¡")
        return
    
    print(f"\næ‰¾åˆ° {len(tasks)} ä¸ªå·²å®Œæˆçš„ä»»åŠ¡:")
    for i, task in enumerate(tasks, 1):
        print(f"{i}. [{task['taskId']}] {task['name']}")
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªä»»åŠ¡è¿›è¡Œæµ‹è¯•
    selected_task = tasks[0]
    task_id = selected_task['taskId']
    
    print(f"\né€‰æ‹©ä»»åŠ¡: {selected_task['name']} (ID: {task_id})")
    
    # è¿è¡Œæµ‹è¯•
    unified_objects, report = test_tracking_merger(task_id)
    
    # å¯¹æ¯”åˆ†æ
    compare_before_after(task_id)


if __name__ == "__main__":
    main()
